{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp6ntSux4l7Ay5YetoFUYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koleshjr/ALL_MY_TEMPLATES/blob/main/PseudoLabelling_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQuv8FsyD8SE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Rewritten code with pseudolabelling\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    n_estimators=10000,\n",
        "    learning_rate=0.01124,\n",
        "    auto_class_weights='Balanced',\n",
        "    # class_weight='balanced'\n",
        ")\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "oof = np.zeros(len(train_df))\n",
        "predictions = []\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(skfold.split(X, y)):\n",
        "    print(f'Fold {fold + 1}')\n",
        "    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
        "    \n",
        "    # Pseudolabelling\n",
        "    # Get the model predictions on the test set\n",
        "    test_preds = model.predict_proba(test_df[X.columns])[:, 1]\n",
        "    # Get the most confident predictions\n",
        "    confident_preds_high = np.where(test_preds > 0.95)\n",
        "    confident_preds_low = np.where(test_preds < 0.05)\n",
        "    # Add these predictions to the X_train and y_train\n",
        "    X_pseudo_high = test_df.iloc[confident_preds_high[0], :]\n",
        "    X_pseudo_low = test_df.iloc[confident_preds_low[0], :]\n",
        "    X_pseudo = pd.concat([X_pseudo_high, X_pseudo_low])\n",
        "    y_pseudo_high = test_preds[confident_preds_high[0]]\n",
        "    y_pseudo_low = 1 - test_preds[confident_preds_low[0]]\n",
        "    y_pseudo = np.concatenate([y_pseudo_high, y_pseudo_low])\n",
        "    X_train = pd.concat([X_train, X_pseudo])\n",
        "    y_train = np.concatenate([y_train, y_pseudo])\n",
        "    \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=(X_valid, y_valid),\n",
        "        verbose=100,\n",
        "        early_stopping_rounds=250,\n",
        "    )\n",
        "\n",
        "    oof[val_idx] = model.predict(X_valid)\n",
        "    predictions.append(model.predict_proba(test_df[X.columns])[:, 1])\n",
        "\n",
        "predictions = np.mean(predictions, axis=0)\n",
        "print(f'Our oof f1 score is {f1_score(y, oof)}')"
      ]
    }
  ]
}